{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Platform Administration Overview","text":"<p>BREAKING CHANGES: consult the section Upgrade notes for release 0.14 before upgrading your environment.</p> <p>When deploying in a production environment, the platform setup requires additional steps for its secure and efficient use. In this section we take into account aspects that are required for the platform setup. </p> <ul> <li>Authentication and Access Control</li> <li>Platform Configuration</li> </ul>"},{"location":"authentication/","title":"Platform Authentication and Access Control","text":"<p>The DigitalHub Platform supports authentication with an external provider.</p> <p>It is mandatory to set custom values for the platform, so Helm knowledge is required.</p> <p>This section will show how to set an authentication for the following:</p> <ul> <li>Coder</li> <li>Core</li> <li>Dashboard</li> <li>Kubernetes Resource Manager</li> </ul>"},{"location":"configuration/","title":"Platform Configuration","text":"<p>The DigitalHub Platform provides configuration options in the DigitalHub values.yaml file.</p> <p>The safest way to set up your custom values is to use a values file in which you will set up the options you are interested in.</p> <p>Thanks to the Helm hereditary properties, the platform values will change taking the values of your custom file, preserving the integrity of the originals and allowing you to use a shorter set of customized values.</p> <p>You can use a custom set of values from a file like the example below, in which we install digitalhub with custom values: <pre><code>helm upgrade -n &lt;YOUR_NAMESPACE&gt; &lt;YOUR_RELEASE&gt; digitalhub/digitalhub --install --create-namespace --timeout 45m0s --values &lt;YOUR_VALUES_FILE_PATH&gt;\n</code></pre> In this example, <code>--set global.registry.url=\"MINIKUBE_IP_ADDRESS\"</code> and <code>--set global.externalHostAddress=\"MINIKUBE_IP_ADDRESS\"</code> are not specified in the installation command, but they can be specified in your values file:</p> <pre><code>global:\n  registry:\n    url: \"YOUR_ADDRESS\"\n  externalHostAddress: &amp;globalExternalUrl \"YOUR_ADDRESS\"\n</code></pre>"},{"location":"ingress/","title":"Ingress configuration","text":"<p>The services of the platform can be exposed with Ingress by editing your values file.</p> <p>For every exposable component, you will find a value field for the ingress, set by default to enabled: false.</p> <p>After setting enabled to true to activate the Ingress creation, check the component's values.yaml file to see how you should structure your custom values file and set all the neeeded Ingress values.</p> <p>The example below is for the Core Ingress:</p> <pre><code>ingress:\n  enabled: true\n  className: \"youringressclass\"\n  hosts:\n    - host: your.host\n      paths: \n        - pathType: ImplementationSpecific\n          path: /\n  tls:\n  - secretName: yourTlsSecret\n</code></pre>"},{"location":"installation/","title":"Installation on cluster","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Helm</li> <li>Kubectl</li> <li>A configured image registry</li> <li>A configured DNS</li> <li>Domains and Ingress Controller for service exposition</li> <li>A configured OAuth provider to enable authentication</li> </ul>"},{"location":"installation/#installation","title":"Installation","text":"<p>Once you have set your custom values.yaml file, DigitalHub can be installed as follows:</p> <p>1) Add Digitalhub repository: <pre><code>helm repo add digitalhub https://scc-digitalhub.github.io/digitalhub/\n</code></pre></p> <p>2) Install DigitalHub with Helm and your custom values.</p> <pre><code>helm upgrade digitalhub digitalhub/digitalhub -n digitalhub --install --create-namespace --values PATH_TO_YOUR_VALUES_FILE --timeout 45m0s\n</code></pre> <p>5) Wait until all pods are in Running or Completed state <pre><code>kubectl --namespace digitalhub get pods\n</code></pre></p> <p>Once installed, you should see the references (URLs) for the different tools of the platform, similar to the example below: <pre><code>##########################################################\n#   _____   _       _           _ _     _       _        #\n#  (____ \\ (_)     (_)_        | | |   | |     | |       #\n#   _   \\ \\ _  ____ _| |_  ____| | |__ | |_   _| | _     #\n#  | |   | | |/ _  | |  _)/ _  | |  __)| | | | | || \\    #\n#  | |__/ /| ( ( | | | |_( ( | | | |   | | |_| | |_) )   #\n#  |_____/ |_|\\_|| |_|\\___)_||_|_|_|   |_|\\____|____/    #\n#            (_____|                                     #\n#                                                        #\n##########################################################\n\nDigitalhub has been installed. Check its status by running:\n  kubectl --namespace digitalhub get pods\n\nDigitalhub componet URLs:\n  - Dashboard: http://192.168.76.2:30110\n  - Jupyter: http://192.168.76.2:30040 (Create jupyter workspace from template in the coder dashboard before use)\n  - Dremio: http://192.168.76.2:30120 (Create dremio workspace from template in the coder dashboard before use)\n  - Sqlpad: http://192.168.76.2:30140 (Create sqlpad workspace from template in the coder dashboard before use)\n  - Grafana: http://192.168.76.2:30130 (Create grafana workspace from template in the coder dashboard before use)\n  - Docker Registry: http://192.168.76.2:30150\n  - Coder: http://192.168.76.2:30170 (Username: test@digitalhub.test Password: Test12456@!)\n  - Core: http://192.168.76.2:30180\n  - Kubernetes Resource Manager: http://192.168.76.2:30160\n</code></pre></p>"},{"location":"priorityclass/","title":"Priority classes","text":"<p>The Platform's chart provides configuration options for the priority classes of the components provided.</p> <p>You can learn more about Priority and Priority Classes on the official Kubernetes documentation. </p> <p>Keep in mind that priority classes are cluster resources and will affect your whole environment, so previous knowledge of the resource is strictly required before using it.</p> <p>With the configuration options provided, you can:</p> <ul> <li>Set a priority to the components</li> <li>Let the platform chart create the Priority Classes and assign them to the components</li> <li>Use custom Priority Classes that you already defined in your environment</li> </ul> <p>If you enable priority through the Values file, you can specify two priority classes, a high priority one and a low priority:</p> <pre><code>global:\n  #  global.priority -- Priority class configuration\n  priority:\n    #  global.priority.enabled -- Enable/Disable priority classes\n    enabled: true\n    #  global.priority.highPriority -- High priority class configuration\n    highPriority:\n      #  global.priority.highPriority.className -- Name of the high priority class\n      className: &amp;highPriority \"HIGH_PRIORITY_CLASS\"\n      #  global.priority.highPriority.existingClass -- Set this to true if you have an existing priority class with the name specified in className\n      existingClass: false\n      #  global.priority.highPriority.value -- Value of the high priority class created by the chart\n      value: 1000\n    #  global.priority.lowPriority -- Low priority class configuration\n    lowPriority:\n      #  global.priority.lowPriority.className -- Name of the low priority class\n      className: &amp;lowPriority \"LOW_PRIORITY_CLASS\"\n      #  global.priority.lowPriority.existingClass -- Set this to true if you have an existing priority class with the name specified in className\n      existingClass: false\n      #  global.priority.lowPriority.value -- Value of the low priority class created by the chart\n      value: 100\n</code></pre> <p>If <code>global.priority.highPriority/lowPriority.existingClass</code> is set to <code>false</code>, the chart will create these priority classes for you, using <code>className</code> and setting the priority as of <code>value</code>. Vice versa, if <code>global.priority.highPriority/lowPriority.existingClass</code> is set to <code>true</code>, the priority classes will not be created and the ones with the same name as <code>className</code> present on your environment will be used.</p> <p>By default, these two classes use an anchor to assign the classes to the components quickly through the Values file, so check all the components before installing or upgrading the Platform.</p> <p>You are not limited to using only a high priority and a low priority class, you can use as many as you like as long as you create them yourself and specify them in the values.</p> <p>IMPORTANT: The pods generated by the users like Coder workspaces, Core runs and models, have a priority set to the default one present in your environment. Please, keep this in mind when you are planning your hierarchy!</p> <p>Currently, priority classes are supported by the following components with the respective anchor assigned by default:</p> <p>High Priority:</p> <ul> <li>Argo Workflows</li> <li>Core</li> <li>STS (Core)</li> <li>Docker Registry</li> </ul> <p>Low Priority:</p> <ul> <li>API Gateway Operator</li> <li>Dashboard</li> <li>Dremio Rest Server Operator</li> <li>External Postgres Operator</li> <li>Kubernetes Resource Manager</li> <li>Open Web UI</li> <li>PostgRest Operator</li> </ul> <p>To change the priority of a specific component, edit the value of the respective <code>priorityClassName</code> field.</p> <p>For example:</p> <pre><code>core:\n  #  core.priorityClassName -- Name of the priority class to use for the core pods. If not set, no priority class will be used.\n  priorityClassName: \"NAME_OF_YOUR_PRIORITY_CLASS\"\n</code></pre>"},{"location":"upgrading/","title":"Upgrading DigitalHub","text":""},{"location":"upgrading/#upgrade-notes-for-release-014","title":"Upgrade notes for release 0.14","text":"<p>Change of definition for Core runs</p> <p>The definition for Core runs in the database has changed, so it becomes necessary to finish or stop all the current runs before upgrading to the new version.</p> <p>Change of format for Core secrets</p> <p>Core no longer accepts secrets created with a double <code>-</code> in it's name.</p> <p>If you have an ongoing project that still needs your secrets, recreate them with the correct syntax.</p> <p>For example, <code>proj-secrets--test</code> must become <code>proj-secrets--test</code>.</p>"},{"location":"upgrading/#upgrade-procedure","title":"Upgrade procedure","text":"<p>Once the platform is installed, you may find yourself in need of tweaking it and upgrading it.</p> <p>With the command <code>helm upgrade</code> you will be able to change the values of the platform with your custom ones like the example below:</p> <pre><code>helm upgrade -n &lt;NAMESPACE&gt; &lt;RELEASE&gt; digitalhub/digitalhub --timeout 30m0s --values &lt;YOUR_VALUES_FILE_PATH&gt;\n</code></pre> <p>Upgrading Coder templates</p> <p>If you wish to upgrade the Coder templates, you can do so.</p> <p>You can find them in <code>digitalhub/charts/digitalhub/confs/coder</code>.</p> <p>However, it is mandatory to create and set your Coder access token in the values file.</p> <pre><code>coder:\n  template:\n    upgrade:\n      # Set it to true if you want to upgrade the Coder templates.\n      enabled: false\n      # In order to upgrade the templates, you will need to create and set here a Coder Token.\n      token: \"\"\n</code></pre>"},{"location":"authentication/coder/","title":"Coder","text":"<p>To enable the authentication with a provider for Coder, please consult the official Coder documentation.</p> <p>In your provider, the redirect url should correspond to <code>https://yourcoderurl/api/v2/users/oidc/callback</code>.</p>"},{"location":"authentication/core/","title":"Core","text":"<p>To enable the authentication with a provider for Core, you will need to set the values in the file Values.yaml of the chart digitalhub in the Core section.</p> <p>The example below shows only the values concerning the authentication configuration.</p> <pre><code>core:\n  authentication:\n    openId:\n      enabled: true\n      issuerUri: \"https://yourproviderurl\" # Set the issuer url of your provider\n      jwtAudience: \"\" # Set the audience\n      jwtClaim: \"\" # Set the claims\n      oidcClientId: \"\" # Use this if you want to hardcode your clientID\n      scope: \"\" # Specify the scopes\n      externalSecret: # Use this if you want to get the clientID by secret.\n        name: \"\" # Name of the secret\n        key: \"\" # Key of the secret containing the clientID\n</code></pre> <p>In your provider, the redirect url should correspond to <code>https://yourcoreurl/console/auth-callback</code>.</p>"},{"location":"authentication/dashboard/","title":"Dashboard","text":"<p>To enable the authentication with a provider for the Dashboard, you will need to set the values in the file Values.yaml of the chart digitalhub in the Dashboard section.</p> <p>The example below shows only the values concerning the authentication configuration.</p> <pre><code>dashboard:\n  oidc:\n    enabled: true\n    audience:\n      clientId: \"\" # Use this if you want to hardcode your clientID\n      externalSecret: # Use this if you want to get the clientID by secret.\n        name: \"\" # Name of the secret\n        key: \"\" # Key of the secret containing the clientID\n    config:\n      issuer: \"https://yourproviderurl\" # Set the issuer url of your provider\n</code></pre>"},{"location":"authentication/krm/","title":"Kubernetes Resource Manager","text":"<p>To enable the authentication with a provider for Kubernetes Resource Manager, you will need to set the values in the file Values.yaml of the chart digitalhub in the Kubernetes Resource Manager section. </p> <p>The example below shows only the values concerning the authentication configuration.</p> <pre><code>kubernetes-resource-manager:\n  oidc:\n    enabled: true\n    audience:\n      clientId: \"\" # Use this if you want to hardcode your clientID\n      externalSecret: # Use this if you want to get the clientID by secret.\n        name: \"\" # Name of the secret\n        key: \"\" # Key of the secret containing the clientID\n    issuer: \"https://yourproviderurl\" # Set the issuer url of your provider\n    scope: \"\" # Set the scopes\n    authType: \"\" # Set the type of authentication\n</code></pre> <p>In your provider, the redirect url should correspond to <code>https://yourkubernetesresourcemanagerurl/console/auth-callback</code>.</p>"},{"location":"charts/core/keystore/","title":"Keystore","text":"<p>To set up a Keystore for Core, add the following section to your <code>values.yaml</code> file and configure the following fields:</p> <pre><code>core:\n  keystore:\n    existingSecret:\n      secretName: \"keystore-secret\" # Name of the secret containing the keystore\n      keyName: \"keystore.jwks\"    # Name of the key in your keystore secret, should correspond to the keystore file name\n    keystoreKid: \"\"  # Specify the key that the keystore should pick\n    keystorePath: \"/etc/keystore\" # Path where your keystore will be saved\n</code></pre> <p>In this example, a Keystore will be created in the path <code>/etc/keystore/keystore.jwks</code> from a secret called <code>keystore-secret</code>. The key of the secret, <code>keystore.jwks</code>, must contain the base64 encoded keystore.</p>"},{"location":"charts/core/lucene/","title":"Lucene","text":"<p>Lucene is the integrated and default option that Core gives you for performing indexing operations.</p> <p>Lucene is included in Core without the need to configure an external component, all you have to do is set the right values to activate it.</p> <p>Lucene will perform all operations in the directory specified by the value <code>core.lucene.indexPath</code> (defaults to <code>/lucene/</code>); setting this value to <code>false</code> will deactivate the tool entirely.</p> <p>Persistence options will allow you to persist data in a Persistent Volume Claim created for you by the Platform chart. Keep in mind that using <code>ReadWriteOnce</code> or <code>ReadWriteOncePod</code> as Access Mode will set Core's Deployment Strategy Type to <code>Recreate</code>.</p> <p>If you decide to persist your data, once the first indexing operation (during Core's application startup) is done, you can turn <code>core.lucene.reindex</code> value to <code>never</code>.</p> <p>On the opposite, should you disable persistance, it is strongly reccomended to leave the option to <code>always</code>: not doing so will make you lose your Lucene data in case of a restart/crash of the Core Pod.</p> <p>WARNING: Lucene's PVC is provided by the Platform Chart; if you uninstall the release, the PVC will be destroyed, so keep that in mind.</p> <p>Below is an example of Lucene's configuration through the values.yaml file:</p> <pre><code>core:\n  lucene:\n    #  core.lucene.indexPath -- Set the path for Lucene and enables it\n    indexPath: \"/lucene/\"\n    #  core.lucene.persistence -- Lucene persistence configuration\n    persistence:\n      #  core.lucene.persistence.enabled -- Enable persistence for Lucene\n      enabled: true\n      #  core.lucene.persistence.accessMode -- Access mode for the Lucene persistent volume claim\n      accessMode: ReadWriteOnce\n      #  core.lucene.persistence.size -- Size for the Lucene persistent volume claim\n      size: 10Gi\n      #  core.lucene.persistence.storageClass -- Storage class for the Lucene persistent volume claim; if not specified, the default class will be used\n      storageClass: \"\"\n    #  core.lucene.reindex -- Reindex of Lucene\n    reindex: always\n</code></pre>"},{"location":"charts/core/solr/","title":"Solr","text":"<p>Core supports Solr integration for indexing operations.</p> <p>The platform itself does not include Solr, so you will need to set it up by yourself in your environment.</p> <p>Keep in mind that enabling Solr will disable Lucene automatically.</p> <p>Make sure to already create the collection you want to use for Core in your instance.</p>"},{"location":"charts/core/solr/#using-solr-without-authentication","title":"Using Solr without authentication","text":"<p>If you are using a Solr deployment without Basic Authentication enabled, set the following values:</p> <pre><code>core:\n  #  core.solr -- Solr configuration\n  solr:\n    #  core.solr.enabled -- Set this value to true if you want to use Core with an existing Solr instance\n    enabled: true\n    #  core.solr.collection -- Solr collection configuration\n    collection:\n      #  core.solr.collection.name -- Name of the Solr collection\n      name: \"COLLECTION_NAME\"\n    #  core.solr.url -- URL of your Solr instance\n    url: \"SOLR_INSTANCE_URL\"\n</code></pre>"},{"location":"charts/core/solr/#using-solr-with-basic-auth","title":"Using Solr with Basic Auth","text":"<p>If you enabled authentication on your Solr instance you will still need to use the values mentioned in the previous section but you will need to set up some other things.</p> <p>You have two options for the configuration:</p> <ul> <li>Specify just the admin user</li> <li>Specify both admin user and a normal user with permissions to operate on that specific collection</li> </ul> <p>You will have to create a secret containing username and password for each user that you set in the values file.</p> <p>The configuration for the values section can be done like this:</p> <pre><code>core:\n  #  solr -- Solr configuration\n  solr:\n    #  solr.enabled -- Set this value to true if you want to use Core with an existing Solr instance\n    enabled: true\n    #  solr.basicAuth -- Basic Auth configuration of Solr\n    basicAuth:\n      #  solr.basicAuth.enabled -- Set this value to true if you use BasicAuth in your Solr instance\n      enabled: true\n      #  solr.credentials -- Solr credentials configuration\n      credentials:\n        # solr.basicAuth.credentials.existingSecrets -- Existing secrets for Solr Basic Auth configuration\n        existingSecrets:\n          # solr.basicAuth.credentials.existingSecrets.admin -- Existing secret for Solr Basic Auth admin user\n          admin:\n            #  solr.basicAuth.credentials.existingSecrets.admin.passwordKey -- Password key\n            passwordKey: \"PASSWORD_KEY\"\n            #  solr.basicAuth.credentials.existingSecrets.admin.secretName -- Secret name\n            secretName: \"SECRET_NAME\"\n            #  solr.basicAuth.credentials.existingSecrets.admin.usernameKey -- Username key\n            usernameKey: \"USER_KEY\"\n          #  solr.basicAuth.credentials.existingSecrets.user -- Existing secret for Solr Basic Auth user\n          user:\n            #  solr.basicAuth.credentials.existingSecrets.user.passwordKey -- Password key\n            passwordKey: \"PASSWORD_KEY\"\n            #  solr.basicAuth.credentials.existingSecrets.user.secretName -- Secret name\n            secretName: \"SECRET_NAME\"\n            #  solr.basicAuth.credentials.existingSecrets.user.usernameKey -- Username key\n            usernameKey: \"USER_KEY\"\n    #  solr.collection -- Solr collection configuration\n    collection:\n      #  solr.collection.name -- Name of the Solr collection\n      name: \"COLLECTION_NAME\"\n    #  solr.url -- URL of your Solr instance\n    url: \"SOLR_INSTANCE_URL\"\n</code></pre>"},{"location":"charts/core/sts/","title":"STS","text":"<p>WARNING: this feature cannot be used locally as it depends on an Authentication Provider that should be installed in your environment.</p> <p>STS allows you to work with temporary credentials to do operations with a Postgres database, avoiding the use of persistent ones and reducing the risk of a security breach.</p> <p>To activate STS, set <code>core.sts.enabled</code> to <code>true</code>.</p> <p>There are a lot of values to cover, so the example will be divided in three parts.</p>"},{"location":"charts/core/sts/#setting-sts-clientid-and-cliensecret","title":"Setting STS clientId and clienSecret","text":"<p>As a first step, set ClientID and ClientSecret for STS. You can either specify them hardcoded or via secret (better choice for production environments).</p> <pre><code>core:\n  sts:\n    #  sts.enabled -- Enable/Disable STS component for dynamic credentials\n    enabled: false\n    #  sts.client --\n    client:\n      #  sts.client.clientId -- ClientID used by STS\n      clientId: \"\"\n      #  sts.client.clientSecret -- ClientSecret used by STS\n      clientSecret: \"\"\n      #  sts.client.existingSecret --\n      existingSecret:\n        #  sts.client.existingSecret.clientIdKey -- Key corresponding to the STS ClientID\n        clientIdKey: \"CLIENTID\"\n        #  sts.client.existingSecret.clientSecretKey -- Key corresponding to the STS ClientSecret\n        clientSecretKey: \"CLIENTSECRET\"\n        #  sts.client.existingSecret.name -- Name of the secret containing STS ClientID and ClientSecret\n        name: \"YOUR_STS_SECRET\"\n</code></pre>"},{"location":"charts/core/sts/#configuring-sts-database","title":"Configuring STS database","text":"<p>STS itself needs it's own database so you'll need to set the connection with it as well.</p> <p>Here is an example configuration:</p> <pre><code>core:\n  sts:\n    #  core.sts.stsDb -- Values of the STS database\n    stsDb:\n      #  core.sts.stsDb.credentials -- Credentials of the STS database\n      credentials:\n        #  core.sts.stsDb.credentials.existingSecret -- Reference to the secret containing username and password of the STS database user.\n        #  These values have higher priority than the explicit declarations.\n        existingSecret:\n          #  core.sts.stsDb.credentials.existingSecret.name -- Name of the secret containing username and password of the STS database user\n          name: \"YOUR_STS_DB_OWNER\"\n          #  core.sts.stsDb.credentials.existingSecret.passwordKey -- Key corresponding to the STS database user password\n          passwordKey: \"OWNER_PASSWORD_KEY\"\n          #  core.sts.stsDb.credentials.existingSecret.usernameKey -- Key corresponding to the STS database user username\n          usernameKey: \"OWNER_USERNAME_KEY\"\n        #  core.sts.stsDb.credentials.password -- Explicit declaration of the STS database user password.\n        #  It has lower priority than the corresponding secret values.\n        password: \"\"\n        #  core.sts.stsDb.credentials.username -- Explicit declaration of the STS database user username.\n        #  It has lower priority than the corresponding secret values.\n        username: \"\"\n      #  core.sts.stsDb.database -- Name of the STS database\n      database: \"STS_DATABASE_NAME\"\n      #  core.sts.stsDb.driver -- Driver used by the STS database\n      driver: \"STS_DB_DRIVER\"\n      #  core.sts.stsDb.host -- Host of the STS database\n      host: \"STS_DATABASE_HOSTNAME\"\n      #  core.sts.stsDb.platform -- Which kind of database you are using for STS (For example, postgresql)\n      platform: \"postgresql\"\n      #  core.sts.stsDb.port -- STS Database port\n      port: \"5432\"\n      #  core.sts.stsDb.schema -- STS database schema\n      schema: \"public\"\n</code></pre>"},{"location":"charts/core/sts/#configuring-the-database-that-will-use-the-temporary-credentials","title":"Configuring the Database that will use the temporary credentials","text":"<p>Now that you have configured the connection with the STS database, all that's left is configuring the connection with the Platform's main database:</p> <pre><code>core:\n  sts:\n    #  sts.credentials --\n    credentials:\n      #  sts.credentials.roles -- Roles that will be mapped to the user for Database operations.\n      #  Must correspond to the owner user of the Platform's main database.\n      roles: \"OWNER_USER\"\n    #  sts.databaseProvider -- Values of the Platform's main database\n    databaseProvider:\n      #  sts.databaseProvider.enabled -- Enable/Disable dynamic credentials for Postgres operations.\n      enabled: true\n      #  sts.databaseProvider.credentials -- Credentials of the Platform's main database\n      credentials:\n        #  sts.databaseProvider.credentials.existingSecret -- Reference to the secret containing username and password of the Platform's main database owner user.\n        #  These values have higher priority than the explicit declarations.\n        existingSecret:\n          #  sts.databaseProvider.credentials.existingSecret.name -- Name of the secret containing username and password of the Platform's main database owner user\n          name: \"OWNER_SECRET\"\n          #  sts.databaseProvider.credentials.existingSecret.passwordKey -- Key corresponding to the Platform's main database owner user password\n          passwordKey: \"OWNER_PWD\"\n          #  sts.databaseProvider.credentials.existingSecret.usernameKey -- Key corresponding to the Platform's main database owner user username\n          usernameKey: \"OWNER_USERNAME\"\n        #  sts.databaseProvider.credentials.password -- Explicit declaration of the Platform's main database owner user password.\n        #  It has lower priority than the corresponding secret values.\n        password: \"\"\n        #  sts.databaseProvider.credentials.username -- Explicit declaration of the Platform's main database owner user username.\n        #  It has lower priority than the corresponding secret values.\n        username: \"\"\n    #  sts.jwt --\n    jwt:\n      #  sts.jwt.issuerUri -- URL of the JWT issuer.\n      issuerUri: ISSUER_URL\n</code></pre>"},{"location":"charts/core/templates/","title":"Core templates","text":""},{"location":"charts/core/templates/#what-are-core-templates","title":"What are Core templates?","text":"<p>You can create and use custom Core templates for your use cases.</p> <p>With this feature, you will be able to customize the resources generated by Core to achieve your needs, creating some baselines that the users can use for their projects. For example, you could:</p> <ul> <li>Set custom requests and limits</li> <li>Harden the securityContext</li> <li>Add tolerations for GPU usage</li> </ul> <p>Templates can be used as profiles when creating pods, deployments, services and secrets with Core.</p>"},{"location":"charts/core/templates/#create-a-template","title":"Create a template","text":"<p>In order to be used, the templates must be specified in a ConfigMap in the form of values of a key, while the key should be the name of the template file that will be mounted in Core.</p> <p>Be aware that you must create and apply the ConfigMap yourself.</p> <p>You can specify multiple templates in the form of key: value (filename: template) in the same ConfigMap.</p> <p>The following is an example of a template for Core:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: core-templates\ndata:\n  template-example.yaml: |-   # Name of the template file\n    id: template1   \n    name: template1\n    description: Lorem ipsum dolor sit amet, consectetur adipiscing elit. In imperdiet lectus arcu, eget mattis dui varius vitae. Morbi lorem augue, volutpat nec mi sagittis, vulputate congue ligula. Maecenas ac luctus mauris. Ut maximus est convallis nisi porta, vel sodales lorem dictum. Praesent ullamcorper enim accumsan diam pharetra feugiat. Integer maximus tortor et nulla fermentum commodo. In vitae massa nec leo fermentum interdum. Integer consectetur dolor vitae accumsan vulputate. Curabitur placerat suscipit justo tempor placerat. Nam euismod suscipit ante non sollicitudin. Integer at cursus sem.\n    runtimeClass: class1\n    priorityClass: class1\n    envs:\n      - name: ENV1\n        value: VALU123123\n      - name: ENV2\n        value: VALU123123\n    resources:\n      requests:\n        cpu: \"1\"\n        memory: \"1Gi\"\n        nvidia.com/gpu: \"1\"\n        ephemeral-storage: \"10Gi\"\n      limits:\n        cpu: \"5\"\n        memory: \"40Gi\"\n        nvidia.com/gpu: \"1\"\n        ephemeral-storage: \"60Gi\"\n    ---\n    apiVersion: batch/v1\n    kind: Job\n    metadata:\n      name: pi\n    spec:\n      template:\n        spec:\n          containers:\n            - name: pi\n              image: perl:5.34.0\n              command: [\"perl\", \"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"]\n          restartPolicy: Never\n      backoffLimit: 4\n</code></pre> <p><code>template-example.yaml</code> is the key, and it is the name of the template file that will be mounted in Core. The actual template is the value of <code>template-example.yaml</code>, so, in this case:</p> <pre><code>id: template1   \nname: template1\ndescription: Lorem ipsum dolor sit amet, consectetur adipiscing elit. In imperdiet lectus arcu, eget mattis dui varius vitae. Morbi lorem augue, volutpat nec mi sagittis, vulputate congue ligula. Maecenas ac luctus mauris. Ut maximus est convallis nisi porta, vel sodales lorem dictum. Praesent ullamcorper enim accumsan diam pharetra feugiat. Integer maximus tortor et nulla fermentum commodo. In vitae massa nec leo fermentum interdum. Integer consectetur dolor vitae accumsan vulputate. Curabitur placerat suscipit justo tempor placerat. Nam euismod suscipit ante non sollicitudin. Integer at cursus sem.\nruntimeClass: class1\npriorityClass: class1\nenvs:\n  - name: ENV1\n    value: VALU123123\n  - name: ENV2\n    value: VALU123123\nresources:\n  requests:\n    cpu: \"1\"\n    memory: \"1Gi\"\n    nvidia.com/gpu: \"1\"\n    ephemeral-storage: \"10Gi\"\n  limits:\n    cpu: \"5\"\n    memory: \"40Gi\"\n    nvidia.com/gpu: \"1\"\n    ephemeral-storage: \"60Gi\"  \n---\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: pi\nspec:\n  template:\n    spec:\n      containers:\n        - name: pi\n          image: perl:5.34.0\n          command: [\"perl\", \"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"]\n      restartPolicy: Never\n  backoffLimit: 4\n</code></pre> <p>As you can see, the template in the above example is composed of two parts:</p> <ul> <li>The upper part (that will be refered to as Profile)</li> <li>The bottom part (that will be refered to as Base Template)</li> </ul> <p>The template merge process is mainly done in three steps:</p> <p>1) The Base Template is used as the starting point for the resource (in this case, a Job). This part can be modified by the user.</p> <p>2) Core appends it's own configuration to the resource</p> <p>3) The Profile is applied, adding the specified fields to the resource; as a result, the job will have the runtimeClass, priorityClass and two variables specified in the Profile. This part cannot be modified by the user.</p> <p>If you wish so, you can also decide to use a Profile without the Base Template if you want to set just certain values (for example, resources or tolerations).</p>"},{"location":"charts/core/templates/#setting-templates-in-the-valuesyaml-file","title":"Setting templates in the Values.yaml file","text":"<p>The following is a reference for the configuration of Core Templates in the Values.yaml file:</p> <pre><code>core:\n  templates:   # Every item in the list must match a template you have created.\n    - name: template-example\n      path: /templates/template-example.yaml\n  volumeMounts:\n    - name:  templates\n      mountPath:  /templates   # Directory in Core in which the template files will be saved\n  volumes:\n    - name:  templates   # Volume for the templates\n      configMap:\n        name: core-templates   # Must match the ConfigMap containing the templates\n</code></pre> <p>Now you can create resources with your template and profile from Core.</p>"},{"location":"charts/core/templates/#supported-fields","title":"Supported fields","text":"<p>The following is a list of all the fields that you can set in the Profile section. You can find an in depth explanation of how to set these fields in the documentation about Kubernetes Resources</p> Field Format envs List secrets List resources Object volumes List nodeSelector List affinity Object tolerations List runtimeClass String priorityClass String imagePullPolicy String"},{"location":"charts/krm/roles/","title":"KRM roles","text":"<p>Enabling authentication for the Kubernetes Resource Manager is required to use this feature.</p> <p>Setting up roles can be a great way for assigning permissions to the users of the Kubernetes Resource Manager, setting up limitations to what they can do and the resources they can have access to.</p> <p>To set up your custom KRM roles and permissions, follow this example and change the fields to your needs in your Values file:</p> <pre><code>kubernetes-resource-manager:\n  oidc:\n    roleClaim: \"krm_roles\"    # Name of the role used \n    access:\n      roles:\n        - role: ROLE_MY_ROLE  # Name of the role\n          # Resources associated to the role with permissions\n          resources: k8s_service, k8s_secret::read, mycrd/example.com::write\n</code></pre> <p>In this basic example we create a Role called ROLE_MY_ROLE that will have:</p> <ul> <li>Access to the services</li> <li>Access with read permissions to the secrets</li> <li>Access with write permissions to a custom CRD</li> </ul> <p>You will also have to setup your authentication provider accordingly, so that you can associate the correct role to the correct users.</p>"},{"location":"components/hpc/hcp-integration/","title":"Digitalhub Platform: HCP Workload Offloading via Interlink","text":""},{"location":"components/hpc/hcp-integration/#overview","title":"Overview","text":"<p>Digitalhub platform leverages Kubernetes-native orchestration with the capability to dynamically offload machine learning workloads to an external HPC (High Performance Computing) cluster using the InterLink Project. This hybrid approach combines the flexibility of Kubernetes with the raw computational power of HPC resources for demanding ML training and inference tasks.</p>"},{"location":"components/hpc/hcp-integration/#architecture","title":"Architecture","text":"<p>InterLink API and the plugin deployment can be arranged in three different ways across the kubernetes cluster and the remote HPC part. Check InterLink Project documentations to get more informations.</p> <p>In this example we will use the tunneled deployment scenario.</p> <p></p>"},{"location":"components/hpc/hcp-integration/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster (with Digitalhub platform installed)</li> <li>Access to HCP cluster with job scheduler (Slurm, PBS, etc.)</li> <li>Interlink project deployed and configured</li> <li>Network connectivity between clusters</li> <li>Appropriate authentication credentials</li> </ul>"},{"location":"components/hpc/hcp-integration/#kubernetes-configuration","title":"Kubernetes Configuration","text":"<ol> <li> <p>SSH Key Setup Generate an SSH key pair if you don't have one: <pre><code># Generate SSH key pair\nssh-keygen -t rsa -b 4096 -f ~/.ssh/interlink_rsa\n\n# Copy private key to remote server\nscp ~/.ssh/interlink_rsa user@remote-server:~\n\n# Test SSH connection\nssh -i ~/.ssh/interlink_rsa user@remote-server\n</code></pre></p> </li> <li> <p>Interlink Setup Deploy the Interlink on your kubernetes cluster:</p> </li> </ol> <pre><code>helm install --create-namespace -n interlink virtual-node \\\n  oci://ghcr.io/intertwin-eu/interlink-helm-chart/interlink \\\n  --values my-values.yaml\n</code></pre> my-values.yaml<pre><code>nodeName: interlink-socket-node\n\ninterlink:\n  enabled: true\n  socket: unix:///var/run/interlink.sock\n\nplugin:\n  socket: unix:///var/run/plugin.sock\n\nsshBastion:\n  enabled: true\n  clientKeys:\n    authorizedKeys: \"ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAI...\" # Previosly createt public key\n  port: 31022\n\nvirtualNode:\n  resources:\n    CPUs: 8\n    memGiB: 32\n    pods: 100\n</code></pre>"},{"location":"components/hpc/hcp-integration/#hpc-configuration","title":"HPC Configuration","text":"<ol> <li>Download interlink-slurm-plugin on your login node.</li> <li>Configure InterLink Slurm plugin to listen on a Unix socket instead of a TCP port: /root/SlurmConfig.yaml<pre><code>SidecarPort: \"\"\nSocket: \"unix:///var/run/plugin.sock\"\nSbatchPath: \"/usr/bin/sbatch\"\nScancelPath: \"/usr/bin/scancel\"\nSqueuePath: \"/usr/bin/squeue\"\nSinfoPath: \"/usr/bin/sinfo\"\nCommandPrefix: \"\"\nSingularityPrefix: \"\"\nSingularityPath: \"singularity\"\nExportPodData: true\nDataRootFolder: \".local/interlink/jobs/\"\nNamespace: \"vk\"\nTsocks: false\nTsocksPath: \"$WORK/tsocks-1.8beta5+ds1/libtsocks.so\"\nTsocksLoginNode: \"login01\"\nBashPath: /bin/bash\nVerboseLogging: true\nErrorsOnlyLogging: false\nContainerRuntime: singularity\nEnrootDefaultOptions: [\"--rw\"]\nEnrootPrefix: \"\"\nEnrootPath: enroot\n</code></pre></li> <li> <p>On the remote HCP login node, start your interLink plugin: <pre><code># Example: Start SLURM plugin on remote HPC system\ncd /path/to/plugin\nSLURMCONFIGPATH=/root/SlurmConfig.yaml SHARED_FS=true /path/to/plugin/slurm-sidecar\n</code></pre></p> </li> <li> <p>Forward slurm plugin Unix socket to ssh the bastion host: <pre><code>ssh -nNT -L /var/run/plugin.sock:/var/run/plugin.sock user@sshbastiononkubernetes\n</code></pre></p> </li> </ol>"},{"location":"components/hpc/hcp-integration/#post-installation","title":"Post-Installation","text":""},{"location":"components/hpc/hcp-integration/#verify-deployment","title":"Verify Deployment","text":"<pre><code># Check virtual node status\nkubectl get node &lt;nodeName&gt;\n\n# Check pod status\nkubectl get pods -n interlink\n\n# View virtual node details\nkubectl describe node &lt;nodeName&gt;\n\n# Check logs\nkubectl logs -n interlink deployment/&lt;nodeName&gt;-node -c vk\n</code></pre>"},{"location":"components/hpc/hcp-integration/#testing-the-virtual-node","title":"Testing the Virtual Node","text":"<pre><code># test-pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: test-workload\nspec:\n  nodeSelector:\n    kubernetes.io/hostname: &lt;nodeName&gt;\n  containers:\n  - name: test\n    image: busybox\n    command: [\"sleep\", \"3600\"]\n</code></pre> <p>```bash kubectl apply -f test-pod.yaml kubectl get pod test-workload -o wide</p>"},{"location":"components/krm/krm-custom-views/","title":"KRM - Custom views","text":"<p>In Kubernetes Resource Manager, it is possible to customize the pages for creating, listing, inspecting and editing custom resources of a specific kind. As it involves writing React code, and using the React-admin library, familiarity with these technologies may be required, depending on the desired level of customization.</p>"},{"location":"components/krm/krm-custom-views/#create-a-custom-view","title":"Create a custom view","text":"<p>Create a new file, under <code>frontend/src/resources</code>, containing the name of the custom resource definition (CRD), in the format <code>cr.&lt;CRD&gt;.ts</code>. For example, if the CRD is <code>myresource.example.com</code>, the filename will be <code>cr.myresource.example.com.tsx</code>.</p> <p>You are encouraged to use other files within the path as reference on how to write this file. You are expected to define 4 functions, one for each of these actions: Create, List, Show, Edit. Each would have this structure: <pre><code>const CrCreate = () =&gt; { // example for Create\n    ...\n    return (\n        &lt;&gt;\n            ...\n        &lt;/&gt;\n    );\n};\n</code></pre></p> <p>The body of the function will perform any kind of computation that your page may need, while the return segment will contain the form or datagrid to display.</p> <p>Then, register these functions within a view and export it:</p> <pre><code>const CustomView: View = {\n    key: 'myresource.example.com',\n    name: 'My Resource',\n    list: CrList,\n    show: CrShow,\n    create: CrCreate,\n    edit: CrEdit,\n};\n\nexport default CustomView;\n</code></pre>"},{"location":"components/krm/krm-custom-views/#register-the-custom-view","title":"Register the custom view","text":"<p>Once the custom view file is ready, you simply need to register it. Open <code>frontend/src/App.tsx</code> and import the view:</p> <pre><code>import crExample from './resources/cr.myresource.example.com';\n</code></pre> <p>Then, register it by adding a line to the <code>customView</code> structure:</p> <pre><code>const customViews: { [index: string]: View } = {\n    'myresource.example.com': crExample,\n    ...\n};\n</code></pre>"}]}