{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd54d6-b40e-459f-9e7b-d1eb6b790d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b4e397-cac6-4b7d-9f16-4c9d7f4e1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"llm\"\n",
    "project = dh.get_or_create_project(PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c154103-279e-4e87-b035-1cfded701ab3",
   "metadata": {},
   "source": [
    "## Text Classification LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ab6b2-96f8-44ad-a6e0-07b3e1c47604",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_function = project.new_function(\"llm_classification\",\n",
    "                                   kind=\"huggingfaceserve\",\n",
    "                                   model_name=\"mymodel\",\n",
    "                                   path=\"huggingface://distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd6e7434-c44b-4b10-b1ea-c8c99ff86e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_run = llm_function.run(action=\"serve\", profile=\"template-a100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b24d9810-e4d9-41f3-b6a6-3b5ff25d26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_URL = llm_run.refresh().status.to_dict()[\"service\"][\"url\"]\n",
    "MODEL_NAME = \"mymodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04952d03-e154-415c-81a4-e01128f432f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'mymodel', 'model_version': None, 'id': '11eb98d9-c0a4-479f-9dfd-9c58792e8d9b', 'parameters': None, 'outputs': [{'name': 'output-0', 'shape': [2], 'datatype': 'INT64', 'parameters': None, 'data': [1, 0]}]}\n"
     ]
    }
   ],
   "source": [
    "with requests.post(f'http://{SERVICE_URL}/v2/models/{MODEL_NAME}/infer', json={\n",
    "    \"inputs\": [\n",
    "        {\n",
    "        \"name\": \"input-0\",\n",
    "        \"shape\": [2],\n",
    "        \"datatype\": \"BYTES\",\n",
    "        \"data\": [\"Hello, my dog is cute\", \"I am feeling sad\"]\n",
    "        }\n",
    "    ]\n",
    "}) as r:\n",
    "    res = r.json()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa794ec2-47ca-4b69-b256-51fcdbff6e5d",
   "metadata": {},
   "source": [
    "## Text Generation LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af9634-cb2a-4711-9981-c6738a87ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_function = project.new_function(\"llm_generation\",\n",
    "                                   kind=\"huggingfaceserve\",\n",
    "                                   model_name=\"mymodel\",\n",
    "                                   path=\"huggingface://meta-llama/meta-llama-3-8b-instruct\"\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e051b-f93c-4404-9072-03e62c7cfda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_run = llm_function.run(action=\"serve\",\n",
    "                           profile=\"template-a100\",\n",
    "                           env = [{\n",
    "                                \"name\": \"HF_TOKEN\",\n",
    "                                \"value\": \"<HUGGINGFACE TOKEN>\"\n",
    "                            }]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feda17ee-9bfb-4e35-b978-336d91341861",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_URL = llm_run.refresh().status.to_dict()[\"service\"][\"url\"]\n",
    "MODEL_NAME = \"mymodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f2c6b1e-8ff5-4e7f-a3a6-187730afee2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-2826903870a94277978e164880a58e9f', 'choices': [{'finish_reason': 'length', 'index': 0, 'logprobs': None, 'text': \" Hope you're having a great day!\\n\\nHere I'd like to share some news about my new podcast, where I'll be exploring the world of...\"}], 'created': 1724843471, 'model': 'mymodel', 'system_fingerprint': None, 'object': 'text_completion', 'usage': {'completion_tokens': 30, 'prompt_tokens': 7, 'total_tokens': 37}}\n"
     ]
    }
   ],
   "source": [
    "with requests.post(f'http://{SERVICE_URL}/openai/v1/completions', json={\"model\": \"mymodel\", \"prompt\": \"Hello! How are you?\", \"stream\":False, \"max_tokens\": 30}) as r:\n",
    "    res = r.json()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8812ca1e-6933-490a-9368-3e37384fa239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-97af9ba1bebd402ea49e7748d54e37f4', 'choices': [{'finish_reason': 'length', 'index': 0, 'message': {'content': 'O, fairest hues that doth adorn our sight,\\nA world of wonder, in thy tints and bright!\\nThy palette, rich and', 'tool_calls': None, 'role': 'assistant', 'function_call': None}, 'logprobs': None}], 'created': 1724843487, 'model': 'mymodel', 'system_fingerprint': None, 'object': 'chat.completion', 'usage': {'completion_tokens': 30, 'prompt_tokens': 30, 'total_tokens': 60}}\n"
     ]
    }
   ],
   "source": [
    "with requests.post(f'http://{SERVICE_URL}/openai/v1/chat/completions', json={\n",
    "    \"model\": \"mymodel\",\n",
    "    \"messages\":[\n",
    "        {\"role\":\"system\",\"content\":\"You are an assistant that speaks like Shakespeare.\"},\n",
    "        {\"role\":\"user\",\"content\":\"Write a poem about colors\"}\n",
    "    ],\"max_tokens\":30,\n",
    "    \"stream\":False}) as r:\n",
    "    res = r.json()\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
